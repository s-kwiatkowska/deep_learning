#!/usr/bin/env python
# coding: utf-8

# # Dobre praktyki z DeepLearning 
# 
# ### Celem jest wskazanie kilku dobrych praktyk w DL (w szczegÃ³lnoÅ›ci z `Keras` i/lub `Tensorflow`). 

# ## Krok po kroku
# 
# JeÅ›li dopiero zaczynasz przygodÄ™ z Python, to moÅ¼e potrzebujesz dodatkowego wsparcia i wyjaÅ›nienia skÅ‚adni lub tego, co robi ta czy inna funkcja. JeÅ›li tak, to poniÅ¼sze wideo jest dla Ciebie. Krok po kroku przechodzÄ™ po notebooku i wyjaÅ›niam, co tu siÄ™ dzieje.

# In[4]:


get_ipython().run_cell_magic('html', '', '<iframe style="height:500px;width:100%" src="https://bit.ly/3bvjqII" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>')


# ## Callbacks
# 
# Keras posiada sporo rÃ³Å¼nych "callbackÃ³w", rÃ³wnieÅ¼ moÅ¼na zdefiniowaÄ‡ swoje wÅ‚asne. Natomiast warto wiedzieÄ‡ co najmniej o tych:
# - [EarlyStopping](https://bit.ly/2RW4BrR) - umoÅ¼liwia zatrzymanie trenowania modeli jeÅ›li po X epokach model tylko pogarsza siÄ™ (nastÄ™puje overfitting).
# - [ModelCheckpoint](https://bit.ly/3omctim) - umoÅ¼liwia zapisywanie modelu, szczegÃ³lnie zaleÅ¼y nam na zapisywaniu najlepszej wersji (dla ktÃ³rejÅ› epoki, wtedy nie musimy uczyÄ‡ modelu od nowa).
# - [ReduceLROnPlateau](https://bit.ly/3tW21Pz) - umoÅ¼liwia zmniejszenie learning rate, kiedy model zatrzymaÅ‚ siÄ™ (to czasem moÅ¼e pomÃ³c).
# - [PlotLossesCallback](https://bit.ly/3eMQ2j7) - rysowanie krzywej uczenia siÄ™ w Å‚atwiejszy sposÃ³b.
# - [TensorBoard](https://bit.ly/2RlNBLz) - umoÅ¼liwia podpiÄ™cie siÄ™ do `TensorBoard` (pod warunkiem, Å¼e backend mamy `TensorFlow`).

# In[40]:


import os

from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard

import catboost as ctb
from sklearn.datasets import make_regression, make_classification
from sklearn.model_selection import train_test_split

import numpy as np


# In[41]:


(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train.shape, X_test.shape


# In[42]:


# najpierw spÅ‚aszczamy
if len(X_train.shape) == 3:
    num_pixels = X_train.shape[1] * X_train.shape[2]
    X_train = X_train.reshape(X_train.shape[0], num_pixels).astype("float32")
    X_test = X_test.reshape(X_test.shape[0], num_pixels).astype("float32")

print(X_train.shape, X_test.shape)

# skalujemy od 0 do 1
if np.max(X_train) > 1: X_train /= 255
if np.max(X_test) > 1: X_test /= 255

# one-hot encoding dla zmiennej docelowej
if len(y_test.shape) == 1:
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)

    num_classes = y_test.shape[1]


# In[44]:


model = Sequential([
    Dense(512, input_dim=num_pixels, activation='relu'),
    Dense(num_classes, kernel_initializer='normal', activation='softmax')
])
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


# Tworzymy katalog, gdzie bÄ™dÄ… zapisywane informacje podczas trenowania modelu (bÄ™dzie potrzebne np. dla `tensorboard`).

# In[45]:


LOG_DIR = "../logs/tensorboard"
get_ipython().system('mkdir -p "$LOG_DIR"')


# Ustawiamy kilka rÃ³Å¼nych callback'Ã³w.

# In[46]:


callbacks = [ 
    EarlyStopping(patience=4), #jeÅ›li 4 epoki z rzÄ™du nie ma poprawy, to zatrzymaj siÄ™
    ModelCheckpoint('../output/model.best.hdf5', save_best_only=True), # zapis modelu po kaÅ¼dej epoce
    ReduceLROnPlateau(patience=3), #jeÅ›li 3 epoki z rzÄ™du nie ma poprawy, zmniejsz krok (learning_rate)
    TensorBoard(log_dir=LOG_DIR), # odkÅ‚adanie logÃ³w, aby moÅ¼na byÅ‚o uÅ¼yÄ‡ Tensorboard
]

history = model.fit(X_train, y_train,
          batch_size=1024, epochs=5, verbose=1,
          validation_data=(X_test, y_test),
          callbacks=callbacks)


# Model zatrzymaÅ‚ siÄ™ przed wykonaniem 100 epok. WidaÄ‡, Å¼e przed zakoÅ„czeniem zaczÄ™Å‚o nastÄ™powaÄ‡ wypÅ‚aszczanie wynikÃ³w modelu. Najlepszy model zapisaÅ‚ siÄ™ w folderze `output`. 
# 
# **ZwrÃ³Ä‡ uwagÄ™**, Å¼e w tej chwili zmienna `model` posiada stan ostatniej epoki, ktÃ³ra niekoniecznie posiada najlepszy model (prawie nigdy). Dlatego to, co zrobimy teraz, to wczytamy zapisane wagi z `../output/model.best.hdf5`.
# 
# MoÅ¼emy wczytaÄ‡ caÅ‚y model od zera za pomocÄ… `load_model` albo tylko same wagi za pomocÄ…Â `.load_weights`.

# In[47]:


model = load_model('../output/model.best.hdf5')


# W tej chwili mamy zaÅ‚adowany najlepszy model i moÅ¼emy robiÄ‡ predykcjÄ™.

# ## TensorBoard
# 
# MoÅ¼emy sprawdziÄ‡ krzywÄ… uczenia siÄ™ rÃ³wnieÅ¼ przy pomocy `TensorBoard`.  
# ???
# 
# Uruchomiamy TB np. na porcie 8050 (maÅ‚o istotny jest numerek).
# 
# Najpierw uruchom komorke poniÅ¼ej.

# In[62]:


get_ipython().system('tensorboard --logdir=../logs/tensorboard --port=8050 --host=0.0.0.0')


# #  ğŸš¨ğŸš¨ğŸš¨  NastÄ™pnie kliknij ğŸ‘‰ğŸ‘‰ğŸ‘‰ [tutaj](/hub/user-redirect/proxy/8050/) ğŸ‘ˆğŸ‘ˆğŸ‘ˆ

# ZauwaÅ¼, Å¼e poprzednia komÃ³rka bÄ™dzie dziaÅ‚aÄ‡ w nieskoÅ„czonoÅ›Ä‡, chyba Å¼e jÄ… zatrzymamy.
# 
# Dlatego zanim przejdziesz do nastÄ™pnego zadania, naleÅ¼y zatrzymaÄ‡ poprzedniÄ… komÃ³rkÄ™ klikajÄ…c czarny kwadrat w menu.
# 
# ![](../images/stop_cell.png)

# ## Zapisz model
# RÃ³wnieÅ¼ moÅ¼esz samodzielnie zapisywaÄ‡ wagi modelu, a nastÄ™pnie moÅ¼esz je wczytaÄ‡ (np. na serwerze produkcyjnym). Robi siÄ™ to bardzo prosto.

# In[63]:


model.save_weights('../output/my_model_with_some_metadata.h5')


# Wczytywanie wag modelu.

# In[64]:


model.load_weights('../output/my_model_with_some_metadata.h5')


# ## Zadanie 8.4.1
# 
# MajÄ…c informacjÄ™ o `callback`â€™ach, sprÃ³buj wytrenowaÄ‡ model (dowolne zadanie, ktÃ³re robiliÅ›my przed tym) i zapisaÄ‡ wagi. Innymi sÅ‚owy celem tego zadania jest uÅ¼ycie `callbacks` i zapisanie modelu do folderu `output`. BÄ™dzie nam potrzebny w nastÄ™pnym zadaniu.
# 
# PoÅ›wiÄ™Ä‡ na to zadanie maksymalnie 1-2h (w tym czasie gdy trenuje siÄ™ model, moÅ¼esz sprawdziÄ‡ przydatne linki, ktÃ³re sÄ… na dole).

# In[65]:


import tensorflow.keras as keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPool2D
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical

import mnist_reader

get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt


# In[52]:


X_train, y_train = mnist_reader.load_mnist('../input/fashion', kind='train')
X_test, y_test = mnist_reader.load_mnist('../input/fashion', kind='t10k')

print(X_train.shape, X_test.shape)


# In[53]:


img_rows, img_cols = 28, 28

if K.image_data_format() == 'channels_last':
    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)
else:
    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)
    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
    
assert(X_train.shape == (60000, 28, 28, 1))    
assert(X_test.shape == (10000, 28, 28, 1)) 


# In[54]:


# normalizacja danych
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train /= 255
X_test /= 255

num_classes = 10

# one-hot encoding dla zmiennej docelowej
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)


# In[55]:


def get_double_cnn_dropout():
    return Sequential([
        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),
        Conv2D(64, kernel_size=(3, 3), activation='relu'),
        MaxPool2D(pool_size=(2, 2)),
        Dropout(0.25), 

        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same',),
        Conv2D(64, kernel_size=(3, 3), activation='relu'),
        MaxPool2D(pool_size=(2, 2)),
        Dropout(0.25),

        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same',),
        Conv2D(128, kernel_size=(3, 3), activation='relu'),
        MaxPool2D(pool_size=(2, 2)),
        Dropout(0.25),

        Flatten(), # spÅ‚aszczanie danych, aby poÅ‚Ä…czyÄ‡ warstwy konwolucyjne z fully connected layers

        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

model = get_double_cnn_dropout()
model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])

model.summary()


# In[56]:


LOG_DIR = "../logs/tensorboard"
get_ipython().system('mkdir -p "$LOG_DIR"')


# In[57]:


callbacks = [ 
    EarlyStopping(patience=4), #jeÅ›li 4 epoki z rzÄ™du nie ma poprawy, to zatrzymaj siÄ™
    ModelCheckpoint('../output/model.best.hdf5', save_best_only=True), # zapis modelu po kaÅ¼dej epoce
    ReduceLROnPlateau(patience=3), #jeÅ›li 3 epoki z rzÄ™du nie ma poprawy, zmniejsz krok (learning_rate)
    TensorBoard(log_dir=LOG_DIR), # odkÅ‚adanie logÃ³w, aby moÅ¼na byÅ‚o uÅ¼yÄ‡ Tensorboard
]


# In[58]:


history = model.fit(X_train, y_train,
          batch_size=512,
          epochs=5,
          verbose=1,
          validation_data=(X_test, y_test))


# In[59]:


score = model.evaluate(X_test, y_test, verbose=0)
print(f"Test loss: {score[0]}")
print(f"Test accuracy: {score[1]}")

print(f"CNN Error: {100-score[1]*100:.2f}%")


# In[60]:


model.save_weights('../output/my_model_sk.h5')


# In[61]:


model.load_weights('../output/my_model_sk.h5')


# ### ğŸ¤ğŸ—£ï¸ WspÃ³Å‚praca ğŸ’ª i komunikacja ğŸ’¬
# 
# - ğŸ‘‰ [#pml_module8](https://practicalmlcourse.slack.com/archives/C045CQBLK89) - to jest miejsce, gdzie moÅ¼na szukaÄ‡ pomocy i dzieliÄ‡ siÄ™ doÅ›wiadczeniem, takÅ¼e pomagaÄ‡ innym ğŸ¥°. 
# 
# JeÅ›li masz **pytanie z moduÅ‚u 8**, to staraj siÄ™ jak najdokÅ‚adniej je sprecyzowaÄ‡, najlepiej wrzuÄ‡ screen z twoim kodem i bÅ‚Ä™dem, ktÃ³ry siÄ™ pojawiÅ‚ âœ”ï¸
# 
# - ğŸ‘‰ [#pml_module8_done](https://practicalmlcourse.slack.com/archives/C045CQCRAKT) - to miejsce, gdzie moÅ¼esz dzieliÄ‡ siÄ™ swoimi przerobionymi zadaniami, wystarczy, Å¼e wrzucisz screen z #done i numerem lekcji np. *#8.3.3_done*, Å›miaÅ‚o dodaj komentarz, jeÅ›li czujesz takÄ… potrzebÄ™, a takÅ¼e rozmawiaj z innymi o ich rozwiÄ…zaniach ğŸ˜Š 
# 
# - ğŸ‘‰ [#pml_module8_ideas](https://practicalmlcourse.slack.com/archives/C045CQE1B9P)- tutaj moÅ¼esz dzieliÄ‡ siÄ™ swoimi pomysÅ‚ami zwiÄ…zanymi z materiaÅ‚em z tego moduÅ‚u. 

# ## TensorBoard + CatBoost  â¤ï¸
# MÃ³wiÄ…c o `TensorBoard` warto przypomnieÄ‡ algorytm `CatBoost`, ktÃ³ry rÃ³wnieÅ¼ potrafi zintegrowaÄ‡ siÄ™ z `TensorBoard` i rÃ³wnieÅ¼ posiada swÃ³j wÅ‚asny â€œdashboardâ€. SprawdÅºmy to!

# In[ ]:


X, y = make_regression(n_samples=10000, n_features=100, random_state=2019)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)


# Tworzymy katalog, w ktÃ³rym zapiszemy wszystkie informacje zwiÄ…zane z trenowaniem.

# In[ ]:


TRAIN_DIR="../logs/catboost"
get_ipython().system('mkdir -p "$TRAIN_DIR"')


# Trenujemy model.

# In[ ]:


model = ctb.CatBoostRegressor(train_dir=TRAIN_DIR)

model.fit(X_train, y_train, eval_set=(X_test, y_test), logging_level='Silent')
y_pred = model.predict(X_test)


# Uruchamiamy `TensorBoard`.

# In[ ]:


get_ipython().system('tensorboard --logdir=../logs/catboost --port=8050 --host=0.0.0.0')


# #  ğŸš¨ğŸš¨ğŸš¨  NastÄ™pnie kliknij ğŸ‘‰ğŸ‘‰ğŸ‘‰ [tutaj](/hub/user-redirect/proxy/8050/) ğŸ‘ˆğŸ‘ˆğŸ‘ˆ

# ## TensorFlow Serving
# 
# <img src="../images/tf_arch.png" />
# 
# 
# To jest narzÄ™dzie, ktÃ³re zostaÅ‚o przygotowane przez Google do wdraÅ¼ania modeli na produkcjÄ™. W uproszczeniu moÅ¼na powiedzieÄ‡, Å¼e TF Serving martwi siÄ™ za nas, w jaki sposÃ³b efektywnie wykonywaÄ‡ Å¼Ä…dania uÅ¼ytkownikÃ³w (rÃ³wnieÅ¼ potrafi je grupowaÄ‡), jak podmieniaÄ‡ nowe wersje modeli w niezauwaÅ¼alny dla uÅ¼ytkownika sposÃ³b i wiele innych rzeczy. WiÄ™cej moÅ¼na zobaczyÄ‡ np. w tym [video](https://bit.ly/2S0n3PL).
# 
# Jednak `TF Serving` jest doÅ›Ä‡ wymagajÄ…cy i doÅ›Ä‡ ciÄ™Å¼ko jest go zainstalowaÄ‡ np. w ramach kursu. WÅ‚aÅ›ciwie to jest jedna z najwiÄ™kszych trudnoÅ›ci, ktÃ³rÄ… moÅ¼na napotkaÄ‡. Dlaczego sÄ… trudnoÅ›ci? Np. `TF Serving` ma trudnoÅ›ci [ze wsparciem python3](https://bit.ly/3bxRrIu).
# 
# Warto wiedzieÄ‡, Å¼e `TF Serving` istnieje i jeÅ›li tak zdarzy siÄ™, Å¼e bÄ™dziesz budowaÄ‡ modele w `keras/tensorflow`, ktÃ³re trzeba bÄ™dzie dostarczyÄ‡ na produkcjÄ™, to jest to pierwsze narzÄ™dzie, o ktÃ³rym naleÅ¼y pomyÅ›leÄ‡ i sprawdziÄ‡.

# ## Przydatne linki:
# - [Serving Models in Production with TensorFlow Serving](https://bit.ly/2S0n3PL)
# - [How Zendesk Serves TensorFlow Models in Production](https://bit.ly/3uR15NO)
# - [Integrating Keras & TensorFlow: The Keras workflow, expanded](https://bit.ly/3tXKiHS)
# - [How to deploy Machine Learning models with TensorFlow](https://bit.ly/3hr07UN)
# - [Accelerating the Machine Learning Lifecycle with MLflow](https://bit.ly/3hvcdvW)
# - [The What-If Tool: Code-Free Probing of Machine Learning Models](https://bit.ly/3fqkxur)
# - [How to Build Flexible, Portable ML Stacks with Kubeflow and Elastifile (Next Rewind '18)](https://bit.ly/3eSR39z)
# - [Tensorflow in Docker on Kubernetes - Some Pitfalls](https://bit.ly/3eOc1pZ)
# - [Deploying Keras Deep Learning Models with Java](https://bit.ly/2Ql5wkW)
# - [Anaconda, Jupyter Notebook, TensorFlow and Keras for Deep Learning](https://bit.ly/3butzpc)
# 
